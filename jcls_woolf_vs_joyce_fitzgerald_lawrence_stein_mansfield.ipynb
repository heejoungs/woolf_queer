{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is \"queer\" more positive for Woolf than for other modernists?\n",
    "\n",
    "A notebook demonstrating how you could confirm your answer to that question statistically and with confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from smart_open import smart_open\n",
    "import os\n",
    "from gensim import corpora\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap sample \"paragraphs\" from Woolf\n",
    "\n",
    "Instead of paragraphs, we're really going to be using sentence triplets.\n",
    "\n",
    "I'm grouping sentences because I don't know how much the word2vec training runs across sentence boundaries. If it does, randomizing sentences one by one might lose some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\woolfcorpus.txt', encoding = 'latin-1') as f:\n",
    "    woolflines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraphize(linelist): \n",
    "    paragraphlist = []\n",
    "    sentence = []\n",
    "    scount = 0\n",
    "    for line in linelist:\n",
    "        words = line.strip().split()\n",
    "        for w in words:\n",
    "            if not w.endswith('.'):\n",
    "                sentence.append(w)\n",
    "            elif scount < 2:\n",
    "                sentence.append(w)\n",
    "                scount += 1\n",
    "            else:\n",
    "                scount = 0\n",
    "                sentence.append(w)\n",
    "                stext = ' '.join(sentence)\n",
    "                sentence = []\n",
    "                paragraphlist.append(stext)\n",
    "    print(len(linelist), len(paragraphlist))\n",
    "    \n",
    "    return paragraphlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chair.  The curious gleam which had come into all their eyes when\\n'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woolflines[57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166559 31471\n"
     ]
    }
   ],
   "source": [
    "paragraphlist = paragraphize(woolflines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But he stopped. \"And let me know when Mama wants to see me,\" he remarked. Then he paused and pinched his youngest daughter by the ear.'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphlist[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.models\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of positive and negative words\n",
    "\n",
    "There are many such lists in circulation. We happen to be using a list created by Bing Liu, available at\n",
    "\n",
    "https://urldefense.com/v3/__https://ptrckprry.com/course/ssd/data/positive-words.txt*5Cn__;JQ!!DZ3fjg!ocdPDmxGKI3cM5KWMy4Lk5CvwWUKaVGNHHq7NmKxe-bnlu7HeocNyT0goglSyzLN$ \n",
    "https://urldefense.com/v3/__https://ptrckprry.com/course/ssd/data/negative-words.txt*5Cn__;JQ!!DZ3fjg!ocdPDmxGKI3cM5KWMy4Lk5CvwWUKaVGNHHq7NmKxe-bnlu7HeocNyT0gony6LFX4$ \n",
    "citation:\n",
    "\n",
    "Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing and Comparing Opinions on the Web.\" Proceedings of the 14th International World Wide Web conference (WWW-2005), May 10-14, 2005, Chiba, Japan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\liunegative.txt', encoding = 'utf-8') as f:\n",
    "    negative_words = [x.strip() for x in f.readlines()]\n",
    "    \n",
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\liupositive.txt', encoding = 'utf-8') as f:\n",
    "    positive_words = [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(wordlist, model): \n",
    "    vectors = []\n",
    "    \n",
    "    for ex in wordlist:    # for each word in a wordlist\n",
    "        if ex in model.wv:\n",
    "            vec = model.wv[ex]    # get its vector\n",
    "            vectorlength = np.linalg.norm(vec, ord = 2)     # normalize length\n",
    "            vectors.append(vec / vectorlength)              # and save it in a list\n",
    "        \n",
    "    thesum = np.sum(vectors, axis = 0)                  # then add all the vectors\n",
    "    vectorlength = np.linalg.norm(thesum, ord = 2)      # normalize length again\n",
    "    \n",
    "    return thesum / vectorlength\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create multiple Woolf models\n",
    "\n",
    "We're interested in assessing the stability of the thesis that Woolf uses \"queer\" in a more positive sense than Joyce, Fitzgerald, and Lawrence.\n",
    "\n",
    "Can we assert that statement generally? Is it highly dependent on one or two passages, or does it really hold together across the oeuvre of the authors in question?\n",
    "\n",
    "One way to assess this is to run multiple models on different subsamples of both corpora. In each case we can measure the distance from \"queer\" to positive words, and negative words, and the difference between the distances. \n",
    "\n",
    "Since we're measuring distance rather than similarity, the positivity of \"queer\" can be assessed as\n",
    "\n",
    "    negative_distance - positive_distance\n",
    "\n",
    "If we run, say, five models for each corpus, do we see any stable pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.08894485235214233\n",
      "1 0.10514131188392639\n",
      "2 0.024794816970825195\n",
      "3 0.05256707966327667\n",
      "4 0.08833188563585281\n",
      "5 0.04022836312651634\n",
      "6 0.05842835083603859\n",
      "7 0.05726732313632965\n",
      "8 0.06658787280321121\n",
      "9 0.08838743902742863\n"
     ]
    }
   ],
   "source": [
    "woolf_sims = []\n",
    "pos_distances = []\n",
    "neg_distances = []\n",
    "woolf_net_positive = []\n",
    "\n",
    "\n",
    "for i in range (10):\n",
    "    woolfsample = choices(paragraphlist, k = len(paragraphlist))\n",
    "\n",
    "    # random.choices samples with repetition.\n",
    "    # So each time we run this, we're creating a different bootstrap sample of\n",
    "    # \"paragraphs\" from the sentence list.\n",
    "\n",
    "    #loading txt file and turning it into courpus\n",
    "    class MyCorpus:\n",
    "        def __iter__(self):\n",
    "            global woolfsample    \n",
    "            for line in woolfsample:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "    sentences = MyCorpus()\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences, iter=100)\n",
    "\n",
    "    sims = model.wv.most_similar('queer', topn=100)  # get other similar words\n",
    "    woolf_sims.append(sims)\n",
    "\n",
    "    pos_vector = get_vector(positive_words, model)\n",
    "    neg_vector = get_vector(negative_words, model)\n",
    "    vec_queer = model.wv['queer']\n",
    "    \n",
    "    pos_dist = cosine(vec_queer, pos_vector)\n",
    "    neg_dist = cosine(vec_queer, neg_vector)\n",
    "    pos_distances.append(pos_dist)\n",
    "    neg_distances.append(neg_dist)\n",
    "    \n",
    "    net_positive_queer = neg_dist - pos_dist\n",
    "    woolf_net_positive.append(net_positive_queer)\n",
    "    \n",
    "    print(i, net_positive_queer)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"woolf_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "woolf_model = gensim.models.Word2Vec.load(\"woolf_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above tells us, in short, that \"queer\" is always more positive than negative for Woolf. It's not a giant difference, and it varies a lot in size. But there's usually a lean toward the positive.\n",
    "\n",
    "We can also look at the specific distances involved for each run of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.065174975 0.961606834\n",
      "0.932727046 0.851919875\n",
      "0.985136852 0.964738078\n",
      "1.040670883 0.975848475\n",
      "0.934417352 0.780572832\n",
      "1.01196646 1.027640672\n",
      "1.086329013 1.05165549\n",
      "1.049750734 1.012218507\n",
      "1.050694209 0.9168652\n",
      "1.055679008 0.915299304\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(round(neg_distances[i], 9), round(pos_distances[i], 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from smart_open import smart_open\n",
    "import os\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "woolf_vector = woolf_model.wv['queer']  # get numpy vector of queer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('awfully', 0.385651171207428),\n",
       " ('sized', 0.37115126848220825),\n",
       " ('young', 0.36801040172576904),\n",
       " ('suspected', 0.3652426600456238),\n",
       " ('absorption', 0.35453736782073975),\n",
       " ('posing', 0.3511541485786438),\n",
       " ('nice', 0.3499513566493988),\n",
       " ('maisie', 0.3435806930065155),\n",
       " ('oblivion', 0.3387223780155182),\n",
       " ('horrors', 0.32626646757125854),\n",
       " ('speeches', 0.323294073343277),\n",
       " ('evanescent', 0.31067633628845215),\n",
       " ('reputed', 0.3062557578086853),\n",
       " ('just', 0.3011806011199951),\n",
       " ('blotted', 0.30039259791374207),\n",
       " ('buzzing', 0.29972130060195923),\n",
       " ('dreaded', 0.2958635687828064),\n",
       " ('basins', 0.29578498005867004),\n",
       " ('perennial', 0.2948506474494934),\n",
       " ('assuring', 0.29381296038627625),\n",
       " ('booming', 0.2924637198448181),\n",
       " ('bent', 0.2912786900997162),\n",
       " ('hailed', 0.29016220569610596),\n",
       " ('tender', 0.28999805450439453),\n",
       " ('twice', 0.2898043096065521),\n",
       " ('lampsher', 0.28842049837112427),\n",
       " ('walsh', 0.2876507043838501),\n",
       " ('heavens', 0.28620970249176025),\n",
       " ('kissing', 0.2838011384010315),\n",
       " ('caen', 0.28266850113868713),\n",
       " ('pockets', 0.2819019556045532),\n",
       " ('painters', 0.2804553210735321),\n",
       " ('cocking', 0.2803754508495331),\n",
       " ('masculine', 0.2802823781967163),\n",
       " ('stogdon', 0.2793353199958801),\n",
       " ('exploded', 0.27923551201820374),\n",
       " ('comparison', 0.27765434980392456),\n",
       " ('deleterious', 0.27695566415786743),\n",
       " ('slang', 0.2765229046344757),\n",
       " ('squirrels', 0.27599194645881653),\n",
       " ('this', 0.2759091258049011),\n",
       " ('plans', 0.2755843997001648),\n",
       " ('significant', 0.2742382287979126),\n",
       " ('asquith', 0.2739396393299103),\n",
       " ('persian', 0.27252721786499023),\n",
       " ('negligently', 0.27113574743270874),\n",
       " ('tirade', 0.2710320055484772),\n",
       " ('armenians', 0.27095192670822144),\n",
       " ('invalids', 0.27037501335144043),\n",
       " ('omitting', 0.2695590555667877),\n",
       " ('proof', 0.2687683403491974),\n",
       " ('immovable', 0.2673490345478058),\n",
       " ('game', 0.2669960856437683),\n",
       " ('richard', 0.2666792869567871),\n",
       " ('convict', 0.26635780930519104),\n",
       " ('porous', 0.2660123109817505),\n",
       " ('fountains', 0.2658593952655792),\n",
       " ('that', 0.2658226490020752),\n",
       " ('affinity', 0.26559382677078247),\n",
       " ('sucked', 0.26312384009361267),\n",
       " ('cleanliness', 0.2629077136516571),\n",
       " ('contamination', 0.26289427280426025),\n",
       " ('about', 0.26252618432044983),\n",
       " ('happened', 0.26180094480514526),\n",
       " ('equitable', 0.2607996463775635),\n",
       " ('toy', 0.26030367612838745),\n",
       " ('vacancy', 0.26024338603019714),\n",
       " ('innocence', 0.2593679130077362),\n",
       " ('seeming', 0.25934281945228577),\n",
       " ('hovering', 0.2585065960884094),\n",
       " ('smiles', 0.255267858505249),\n",
       " ('hives', 0.25512927770614624),\n",
       " ('suits', 0.25401997566223145),\n",
       " ('roused', 0.25368526577949524),\n",
       " ('transferred', 0.25327783823013306),\n",
       " ('falsehood', 0.25286927819252014),\n",
       " ('accomplishment', 0.25260496139526367),\n",
       " ('hideous', 0.2523527145385742),\n",
       " ('anyhow', 0.25209107995033264),\n",
       " ('dog', 0.2512334883213043),\n",
       " ('different', 0.25067323446273804),\n",
       " ('albanians', 0.2502787411212921),\n",
       " ('craftsman', 0.24852287769317627),\n",
       " ('escaped', 0.24813099205493927),\n",
       " ('cheerless', 0.24807970225811005),\n",
       " ('ascertained', 0.24756474792957306),\n",
       " ('solicitous', 0.24712622165679932),\n",
       " ('judd', 0.24654719233512878),\n",
       " ('crabs', 0.24588340520858765),\n",
       " ('elms', 0.24558645486831665),\n",
       " ('mingling', 0.24504920840263367),\n",
       " ('dangled', 0.244972825050354),\n",
       " ('incompatible', 0.2448458969593048),\n",
       " ('ceremonial', 0.2445395588874817),\n",
       " ('withheld', 0.2444373220205307),\n",
       " ('groom', 0.24392169713974),\n",
       " ('hitching', 0.24377071857452393),\n",
       " ('diction', 0.2436273694038391),\n",
       " ('mentioned', 0.24321354925632477),\n",
       " ('tidy', 0.24286895990371704)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woolf_sims = woolf_model.wv.most_similar('queer', topn=100)  # get top100 similar words\n",
    "woolf_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "# blob = TextBlob('woolflines')\n",
    "# print(blob.noun_phrases[:100])\n",
    "# #model.wv.index2word[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "# for synset in list(wn.all_synsets('a')):\n",
    "#     print (synset[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run multiple models for Joyce, Fitzgerald, and Lawrence\n",
    "\n",
    "We'll just repeat the same steps. First load and paragraphize the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\joyce_fitzgerald_lawrence_corpus.txt', encoding = 'latin-1') as f:\n",
    "    jfllines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410809 75300\n"
     ]
    }
   ],
   "source": [
    "jflparagraphs = paragraphize(jfllines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run five models and measure net positivity in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.00039571523666381836\n",
      "1 0.009407490491867065\n",
      "2 0.006212443113327026\n",
      "3 0.0060949623584747314\n",
      "4 0.010232746601104736\n",
      "5 0.011112898588180542\n",
      "6 0.0028150975704193115\n",
      "7 -0.0005139410495758057\n",
      "8 0.010259002447128296\n",
      "9 0.006488680839538574\n"
     ]
    }
   ],
   "source": [
    "jfl_sims = []\n",
    "jfl_pos_distances = []\n",
    "jfl_neg_distances = []\n",
    "jfl_net_positive = []\n",
    "\n",
    "for i in range(10):\n",
    "    jflsample = choices(jflparagraphs, k = len(jflparagraphs))\n",
    "\n",
    "    # random.choices samples with repetition.\n",
    "    # So each time we run this, we're creating a different bootstrap sample of\n",
    "    # \"paragraphs\" from the sentence list.\n",
    "\n",
    "    #loading txt file and turning it into courpus\n",
    "    class MyCorpus:\n",
    "        def __iter__(self):\n",
    "            global jflsample    \n",
    "            for line in jflsample:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "    sentences = MyCorpus()\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences, iter=5)\n",
    "\n",
    "    sims = model.wv.most_similar('queer', topn=100)  # get other similar words\n",
    "    jfl_sims.append(sims)\n",
    "\n",
    "    pos_vector = get_vector(positive_words, model)\n",
    "    neg_vector = get_vector(negative_words, model)\n",
    "    vec_queer = model.wv['queer']\n",
    "    \n",
    "    pos_dist = cosine(vec_queer, pos_vector)\n",
    "    neg_dist = cosine(vec_queer, neg_vector)\n",
    "    jfl_pos_distances.append(pos_dist)\n",
    "    jfl_neg_distances.append(neg_dist)\n",
    "    \n",
    "    net_positive_queer = neg_dist - pos_dist\n",
    "    jfl_net_positive.append(net_positive_queer)\n",
    "    \n",
    "    print(i, net_positive_queer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for these authors, the word \"queer\" is usually slightly more negative than positive. It's not always true! There's one positive number, which does overlap slightly with a couple of Woolf's models. But it looks like the central tendency here is pretty different from the tendency for Woolf.\n",
    "\n",
    "Let's confirm that formally, using [a T test.](https://urldefense.com/v3/__https://www.scribbr.com/statistics/t-test/__;!!DZ3fjg!ocdPDmxGKI3cM5KWMy4Lk5CvwWUKaVGNHHq7NmKxe-bnlu7HeocNyT0goouiEOj9$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=8.809998941246375, pvalue=6.044038017650719e-08)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(woolf_net_positive, jfl_net_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p value there tells us that the difference of means between these samples would not be very likely to occur by chance if these samples were drawn from populations that actually had the same mean value.\n",
    "\n",
    "You can say confidently that this word is more positive for Woolf than it is for Joyce, Fitzgerald, and Lawrence (considered collectively). How far this holds for each of those three authors individually would be a separate question â€” but that's also probably much further than you need to go in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplotdata = pd.DataFrame({'net_positivity': woolf_net_positive + jfl_net_positive, 'author': ['Woolf'] * 10 + ['JFL'] * 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(6, 8)})\n",
    "sns_plot = sns.boxplot(x = 'author', y = 'net_positivity', data = boxplotdata)\n",
    "fig = sns_plot.get_figure()\n",
    "plt.title(\"Stability Test for Woolf and JFL\")\n",
    "fig.savefig(\"boxplot_woolf_jfl.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This time, let's get individual male authors. Let's start with Joyce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\joycecorpus.txt', encoding = 'latin-1') as f:\n",
    "    jlines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33647 9609\n"
     ]
    }
   ],
   "source": [
    "jparagraphs = paragraphize(jlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.08010598178952932\n",
      "1 -0.01801946002524346\n",
      "2 -0.06052171438932419\n",
      "3 0.09925282839685678\n",
      "4 0.022665901109576225\n",
      "5 0.03449156507849693\n",
      "6 0.01667952537536621\n",
      "7 0.0804000124335289\n",
      "8 0.01219874620437622\n",
      "9 0.026810776442289352\n"
     ]
    }
   ],
   "source": [
    "j_sims = []\n",
    "j_pos_distances = []\n",
    "j_neg_distances = []\n",
    "j_net_positive = []\n",
    "\n",
    "for i in range(10):\n",
    "    jsample = choices(jparagraphs, k = len(jparagraphs))\n",
    "\n",
    "    # random.choices samples with repetition.\n",
    "    # So each time we run this, we're creating a different bootstrap sample of\n",
    "    # \"paragraphs\" from the sentence list.\n",
    "\n",
    "    #loading txt file and turning it into courpus\n",
    "    class MyCorpus:\n",
    "        def __iter__(self):\n",
    "            global jsample    \n",
    "            for line in jsample:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "    sentences = MyCorpus()\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences, iter=100)\n",
    "\n",
    "    sims = model.wv.most_similar('queer', topn=100)  # get other similar words\n",
    "    j_sims.append(sims)\n",
    "\n",
    "    pos_vector = get_vector(positive_words, model)\n",
    "    neg_vector = get_vector(negative_words, model)\n",
    "    vec_queer = model.wv['queer']\n",
    "    \n",
    "    pos_dist = cosine(vec_queer, pos_vector)\n",
    "    neg_dist = cosine(vec_queer, neg_vector)\n",
    "    j_pos_distances.append(pos_dist)\n",
    "    j_neg_distances.append(neg_dist)\n",
    "    \n",
    "    net_positive_queer = neg_dist - pos_dist\n",
    "    j_net_positive.append(net_positive_queer)\n",
    "    \n",
    "    print(i, net_positive_queer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"joyce_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "joyce_model = gensim.models.Word2Vec.load(\"joyce_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "joyce_vector = joyce_model.wv['queer']  # get numpy vector of queer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nun', 0.3792240619659424),\n",
       " ('powdered', 0.3705107867717743),\n",
       " ('altogether', 0.3369549512863159),\n",
       " ('cheese', 0.3358839750289917),\n",
       " ('pack', 0.33264657855033875),\n",
       " ('prefect', 0.32653456926345825),\n",
       " ('cuckoo', 0.3261905908584595),\n",
       " ('soft', 0.32115882635116577),\n",
       " ('suggested', 0.3194236755371094),\n",
       " ('cracked', 0.31320178508758545),\n",
       " ('beds', 0.3108353018760681),\n",
       " ('shocked', 0.30936580896377563),\n",
       " ('taylor', 0.30912548303604126),\n",
       " ('boiled', 0.30222538113594055),\n",
       " ('bands', 0.29382309317588806),\n",
       " ('wells', 0.28951042890548706),\n",
       " ('bath', 0.2879488468170166),\n",
       " ('relief', 0.2868059575557709),\n",
       " ('clean', 0.28262627124786377),\n",
       " ('cissy', 0.2799057960510254),\n",
       " ('roast', 0.2779049575328827),\n",
       " ('different', 0.27579188346862793),\n",
       " ('loafer', 0.2747100591659546),\n",
       " ('stinking', 0.2744004726409912),\n",
       " ('out', 0.27226200699806213),\n",
       " ('mutton', 0.27018246054649353),\n",
       " ('delicate', 0.26971015334129333),\n",
       " ('thorns', 0.26944470405578613),\n",
       " ('rosy', 0.2676074504852295),\n",
       " ('dark', 0.2675609886646271),\n",
       " ('undressed', 0.26702576875686646),\n",
       " ('pins', 0.26641789078712463),\n",
       " ('pisser', 0.26615965366363525),\n",
       " ('till', 0.2657647728919983),\n",
       " ('sly', 0.26446130871772766),\n",
       " ('besides', 0.26430055499076843),\n",
       " ('sick', 0.26373979449272156),\n",
       " ('cakes', 0.26038670539855957),\n",
       " ('earnest', 0.25775033235549927),\n",
       " ('confusion', 0.25715571641921997),\n",
       " ('chapter', 0.2551943063735962),\n",
       " ('never', 0.2537081837654114),\n",
       " ('jenny', 0.2531886100769043),\n",
       " ('loudly', 0.25296926498413086),\n",
       " ('homeward', 0.24927285313606262),\n",
       " ('thats', 0.24860072135925293),\n",
       " ('officer', 0.2484685331583023),\n",
       " ('falling', 0.24748922884464264),\n",
       " ('whole', 0.2463352382183075),\n",
       " ('corned', 0.2462577223777771),\n",
       " ('louder', 0.2461872100830078),\n",
       " ('walk', 0.24601420760154724),\n",
       " ('greasy', 0.2452748715877533),\n",
       " ('cruel', 0.24454012513160706),\n",
       " ('cantwell', 0.24295096099376678),\n",
       " ('fried', 0.24243919551372528),\n",
       " ('oil', 0.24151651561260223),\n",
       " ('curly', 0.240977481007576),\n",
       " ('belt', 0.23958976566791534),\n",
       " ('joe', 0.23868495225906372),\n",
       " ('perfume', 0.23799628019332886),\n",
       " ('limp', 0.23722438514232635),\n",
       " ('stale', 0.23713418841362),\n",
       " ('fountain', 0.23705017566680908),\n",
       " ('fellows', 0.2348673790693283),\n",
       " ('exquisite', 0.23434896767139435),\n",
       " ('doctor', 0.23419639468193054),\n",
       " ('spelling', 0.23232290148735046),\n",
       " ('tupper', 0.23226355016231537),\n",
       " ('loop', 0.23226051032543182),\n",
       " ('wins', 0.2322537899017334),\n",
       " ('buck', 0.23213046789169312),\n",
       " ('free', 0.23212629556655884),\n",
       " ('slender', 0.23196154832839966),\n",
       " ('foreman', 0.2304447591304779),\n",
       " ('bang', 0.22999893128871918),\n",
       " ('ilk', 0.22807995975017548),\n",
       " ('expressive', 0.2263084352016449),\n",
       " ('owe', 0.22611455619335175),\n",
       " ('turf', 0.22502094507217407),\n",
       " ('servants', 0.22501033544540405),\n",
       " ('author', 0.22378072142601013),\n",
       " ('leather', 0.22323769330978394),\n",
       " ('principle', 0.22289693355560303),\n",
       " ('bolt', 0.22281278669834137),\n",
       " ('nicer', 0.22245903313159943),\n",
       " ('shiver', 0.2190207839012146),\n",
       " ('easier', 0.21886694431304932),\n",
       " ('rats', 0.21880437433719635),\n",
       " ('appetite', 0.21876950562000275),\n",
       " ('threshold', 0.2186143845319748),\n",
       " ('eye', 0.2180461883544922),\n",
       " ('extent', 0.21751654148101807),\n",
       " ('worst', 0.21734583377838135),\n",
       " ('infirmary', 0.21727633476257324),\n",
       " ('no', 0.21709147095680237),\n",
       " ('healing', 0.21601811051368713),\n",
       " ('hid', 0.21554699540138245),\n",
       " ('holy', 0.21542835235595703),\n",
       " ('before', 0.2144639492034912)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joyce_sims = joyce_model.wv.most_similar('queer', topn=100)  # get top100 similar words\n",
    "joyce_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.8026393506001015, pvalue=0.0882141903600226)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(woolf_net_positive, j_net_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it is Fitzgerald's turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\fitzgeraldcorpus.txt', encoding = 'latin-1') as f:\n",
    "    flines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83012 11290\n"
     ]
    }
   ],
   "source": [
    "fparagraphs = paragraphize(flines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0018236488103866577\n",
      "1 0.02572246640920639\n",
      "2 -0.026565149426460266\n",
      "3 -0.003229372203350067\n",
      "4 0.006882704794406891\n",
      "5 -0.000397317111492157\n",
      "6 0.008908018469810486\n",
      "7 -0.012672241777181625\n",
      "8 0.0472421795129776\n",
      "9 0.005231186747550964\n"
     ]
    }
   ],
   "source": [
    "f_sims = []\n",
    "f_pos_distances = []\n",
    "f_neg_distances = []\n",
    "f_net_positive = []\n",
    "\n",
    "for i in range(10):\n",
    "    fsample = choices(fparagraphs, k = len(fparagraphs))\n",
    "\n",
    "    # random.choices samples with repetition.\n",
    "    # So each time we run this, we're creating a different bootstrap sample of\n",
    "    # \"paragraphs\" from the sentence list.\n",
    "\n",
    "    #loading txt file and turning it into courpus\n",
    "    class MyCorpus:\n",
    "        def __iter__(self):\n",
    "            global fsample    \n",
    "            for line in fsample:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "    sentences = MyCorpus()\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences, iter=100)\n",
    "\n",
    "    sims = model.wv.most_similar('queer', topn=100)  # get other similar words\n",
    "    f_sims.append(sims)\n",
    "\n",
    "    pos_vector = get_vector(positive_words, model)\n",
    "    neg_vector = get_vector(negative_words, model)\n",
    "    vec_queer = model.wv['queer']\n",
    "    \n",
    "    pos_dist = cosine(vec_queer, pos_vector)\n",
    "    neg_dist = cosine(vec_queer, neg_vector)\n",
    "    f_pos_distances.append(pos_dist)\n",
    "    f_neg_distances.append(neg_dist)\n",
    "    \n",
    "    net_positive_queer = neg_dist - pos_dist\n",
    "    f_net_positive.append(net_positive_queer)\n",
    "    \n",
    "    print(i, net_positive_queer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"fitzgerald_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "fitzgerald_model = gensim.models.Word2Vec.load(\"fitzgerald_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitzgerald_vector = fitzgerald_model.wv['queer']  # get numpy vector of queer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hesitantly', 0.43116316199302673),\n",
       " ('guilty', 0.3615807592868805),\n",
       " ('uneasiness', 0.35936224460601807),\n",
       " ('bring', 0.35395413637161255),\n",
       " ('interior', 0.3476064205169678),\n",
       " ('despising', 0.332146018743515),\n",
       " ('parmelee', 0.3299785256385803),\n",
       " ('reproof', 0.3299705386161804),\n",
       " ('witch', 0.32758599519729614),\n",
       " ('awkwardly', 0.3237317204475403),\n",
       " ('everything', 0.32162269949913025),\n",
       " ('unhappiness', 0.3191125988960266),\n",
       " ('jerked', 0.31760329008102417),\n",
       " ('invest', 0.31638196110725403),\n",
       " ('steamer', 0.3152310848236084),\n",
       " ('golf', 0.30788367986679077),\n",
       " ('sweaters', 0.30422016978263855),\n",
       " ('hazel', 0.3033890724182129),\n",
       " ('rendezvous', 0.30247998237609863),\n",
       " ('twisting', 0.3012869358062744),\n",
       " ('balls', 0.30094122886657715),\n",
       " ('responsible', 0.2998502552509308),\n",
       " ('finals', 0.2941034436225891),\n",
       " ('fox', 0.29403263330459595),\n",
       " ('talks', 0.2923775911331177),\n",
       " ('sordid', 0.2913074493408203),\n",
       " ('neatly', 0.29130738973617554),\n",
       " ('first', 0.2902214825153351),\n",
       " ('rudely', 0.29006168246269226),\n",
       " ('wit', 0.28796282410621643),\n",
       " ('park', 0.2873416543006897),\n",
       " ('polo', 0.28171974420547485),\n",
       " ('eddie', 0.27704116702079773),\n",
       " ('howard', 0.2768615484237671),\n",
       " ('record', 0.2752876877784729),\n",
       " ('college', 0.27438968420028687),\n",
       " ('reports', 0.2718828022480011),\n",
       " ('reckon', 0.27156591415405273),\n",
       " ('bothering', 0.2678157091140747),\n",
       " ('murmuring', 0.2658775746822357),\n",
       " ('psychological', 0.2658332586288452),\n",
       " ('heck', 0.26564472913742065),\n",
       " ('newly', 0.26408180594444275),\n",
       " ('coney', 0.2637746334075928),\n",
       " ('aronstael', 0.26368528604507446),\n",
       " ('lose', 0.26318076252937317),\n",
       " ('dinners', 0.26300138235092163),\n",
       " ('fishing', 0.2625686228275299),\n",
       " ('sergeant', 0.26211294531822205),\n",
       " ('smiles', 0.26115259528160095),\n",
       " ('languid', 0.2600589990615845),\n",
       " ('impatiently', 0.25905734300613403),\n",
       " ('owner', 0.25901228189468384),\n",
       " ('games', 0.25830620527267456),\n",
       " ('tompkins', 0.25792649388313293),\n",
       " ('poignancy', 0.2577921748161316),\n",
       " ('anyhow', 0.25647276639938354),\n",
       " ('dodged', 0.253551185131073),\n",
       " ('fugitive', 0.2526809573173523),\n",
       " ('sight', 0.25244367122650146),\n",
       " ('know', 0.2523152828216553),\n",
       " ('peeper', 0.25229135155677795),\n",
       " ('property', 0.25223714113235474),\n",
       " ('interfere', 0.25164374709129333),\n",
       " ('hurt', 0.25127407908439636),\n",
       " ('rake', 0.2509169578552246),\n",
       " ('grew', 0.24951162934303284),\n",
       " ('wearied', 0.24938452243804932),\n",
       " ('dewy', 0.24929487705230713),\n",
       " ('coupÃ£', 0.24888074398040771),\n",
       " ('eat', 0.24722862243652344),\n",
       " ('presence', 0.24615256488323212),\n",
       " ('planes', 0.2461368441581726),\n",
       " ('wildly', 0.2449653595685959),\n",
       " ('takes', 0.2448270320892334),\n",
       " ('ridiculous', 0.24476146697998047),\n",
       " ('went', 0.24455322325229645),\n",
       " ('excitedly', 0.2442104071378708),\n",
       " ('often', 0.2437421679496765),\n",
       " ('some', 0.24358202517032623),\n",
       " ('baseball', 0.24304939806461334),\n",
       " ('seventeen', 0.24292108416557312),\n",
       " ('bedroom', 0.242874413728714),\n",
       " ('brains', 0.2425682544708252),\n",
       " ('motel', 0.2422669529914856),\n",
       " ('impersonal', 0.24122491478919983),\n",
       " ('uneasily', 0.24068023264408112),\n",
       " ('silence', 0.23962147533893585),\n",
       " ('provoked', 0.23961839079856873),\n",
       " ('hilarious', 0.2393280416727066),\n",
       " ('michigan', 0.2389044463634491),\n",
       " ('coy', 0.23878397047519684),\n",
       " ('tearing', 0.2385680079460144),\n",
       " ('quickened', 0.2385469526052475),\n",
       " ('compact', 0.23806695640087128),\n",
       " ('soda', 0.23806025087833405),\n",
       " ('toilet', 0.23796683549880981),\n",
       " ('lockheart', 0.23747166991233826),\n",
       " ('discarded', 0.23606161773204803),\n",
       " ('whartons', 0.23504644632339478)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitzgerald_sims = fitzgerald_model.wv.most_similar('queer', topn=100)  # get top100 similar words\n",
    "fitzgerald_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=4.048380714089884, pvalue=0.0007540572823165007)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(woolf_net_positive, f_net_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's get Lawrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\lawrencecorpus.txt', encoding = 'latin-1') as f:\n",
    "    llines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294149 54401\n"
     ]
    }
   ],
   "source": [
    "lparagraphs = paragraphize(llines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.08014212548732758\n",
      "1 -0.08231811225414276\n",
      "2 -0.0074689388275146484\n",
      "3 -0.013492494821548462\n",
      "4 -0.12686562538146973\n",
      "5 -0.10750700533390045\n",
      "6 -0.032393425703048706\n",
      "7 -0.020033538341522217\n",
      "8 -0.07783752679824829\n",
      "9 -0.06345993280410767\n"
     ]
    }
   ],
   "source": [
    "l_sims = []\n",
    "l_pos_distances = []\n",
    "l_neg_distances = []\n",
    "l_net_positive = []\n",
    "\n",
    "for i in range(10):\n",
    "    lsample = choices(lparagraphs, k = len(lparagraphs))\n",
    "\n",
    "    # random.choices samples with repetition.\n",
    "    # So each time we run this, we're creating a different bootstrap sample of\n",
    "    # \"paragraphs\" from the sentence list.\n",
    "\n",
    "    #loading txt file and turning it into courpus\n",
    "    class MyCorpus:\n",
    "        def __iter__(self):\n",
    "            global lsample    \n",
    "            for line in lsample:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "    sentences = MyCorpus()\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences, iter=100)\n",
    "\n",
    "    sims = model.wv.most_similar('queer', topn=100)  # get other similar words\n",
    "    l_sims.append(sims)\n",
    "\n",
    "    pos_vector = get_vector(positive_words, model)\n",
    "    neg_vector = get_vector(negative_words, model)\n",
    "    vec_queer = model.wv['queer']\n",
    "    \n",
    "    pos_dist = cosine(vec_queer, pos_vector)\n",
    "    neg_dist = cosine(vec_queer, neg_vector)\n",
    "    l_pos_distances.append(pos_dist)\n",
    "    l_neg_distances.append(neg_dist)\n",
    "    \n",
    "    net_positive_queer = neg_dist - pos_dist\n",
    "    l_net_positive.append(net_positive_queer)\n",
    "    \n",
    "    print(i, net_positive_queer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Lawrence, it is worth performing a T-test, as we now know that he is the player who is mainly responsible for associating queer with negative words. Below shows that it is unlikely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"lawrence_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "lawrence_model = gensim.models.Word2Vec.load(\"lawrence_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "lawrence_vector = lawrence_model.wv['queer']  # get numpy vector of queer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sly', 0.42787545919418335),\n",
       " ('strange', 0.3886798620223999),\n",
       " ('mocking', 0.3737245202064514),\n",
       " ('curious', 0.3670670986175537),\n",
       " ('alert', 0.36604946851730347),\n",
       " ('handsome', 0.36304062604904175),\n",
       " ('strangest', 0.36125272512435913),\n",
       " ('spasmodic', 0.3550724387168884),\n",
       " ('plangent', 0.3446634113788605),\n",
       " ('characteristic', 0.3357364237308502),\n",
       " ('stony', 0.33411550521850586),\n",
       " ('slight', 0.3323570191860199),\n",
       " ('cultivated', 0.327669233083725),\n",
       " ('sharp', 0.31447330117225647),\n",
       " ('sharper', 0.31212347745895386),\n",
       " ('rusty', 0.31113284826278687),\n",
       " ('suffocating', 0.3106423020362854),\n",
       " ('daintily', 0.31053030490875244),\n",
       " ('piercingly', 0.30837568640708923),\n",
       " ('pleasant', 0.3080192506313324),\n",
       " ('nose', 0.30325496196746826),\n",
       " ('lean', 0.3028942942619324),\n",
       " ('wicked', 0.3028915524482727),\n",
       " ('underlying', 0.3027891218662262),\n",
       " ('deliberate', 0.30159103870391846),\n",
       " ('ageless', 0.30048874020576477),\n",
       " ('unattractive', 0.299973726272583),\n",
       " ('minding', 0.29995831847190857),\n",
       " ('classic', 0.2993857264518738),\n",
       " ('muscular', 0.29921793937683105),\n",
       " ('napkin', 0.298655241727829),\n",
       " ('fucked', 0.29825177788734436),\n",
       " ('wick', 0.29715031385421753),\n",
       " ('sloping', 0.29701730608940125),\n",
       " ('impatiently', 0.2958548665046692),\n",
       " ('little', 0.2951532304286957),\n",
       " ('same', 0.29497188329696655),\n",
       " ('cheeky', 0.29476433992385864),\n",
       " ('laconic', 0.29278916120529175),\n",
       " ('penetrating', 0.2923506498336792),\n",
       " ('kind', 0.29232287406921387),\n",
       " ('stray', 0.2911365032196045),\n",
       " ('lesbian', 0.2907631993293762),\n",
       " ('sturdy', 0.2902873754501343),\n",
       " ('fascinating', 0.29000234603881836),\n",
       " ('timid', 0.28930434584617615),\n",
       " ('shriek', 0.28738847374916077),\n",
       " ('successful', 0.2870839834213257),\n",
       " ('sort', 0.28696131706237793),\n",
       " ('loitered', 0.2866673767566681),\n",
       " ('emotions', 0.28632456064224243),\n",
       " ('borders', 0.28460580110549927),\n",
       " ('poor', 0.2841101884841919),\n",
       " ('smiling', 0.28141599893569946),\n",
       " ('reassuringly', 0.2806960940361023),\n",
       " ('goliath', 0.2804398238658905),\n",
       " ('small', 0.27998778223991394),\n",
       " ('sullen', 0.27923572063446045),\n",
       " ('shy', 0.2791156768798828),\n",
       " ('oui', 0.27819693088531494),\n",
       " ('drifts', 0.2781818211078644),\n",
       " ('soft', 0.27788200974464417),\n",
       " ('piquant', 0.27681416273117065),\n",
       " ('businesslike', 0.27657800912857056),\n",
       " ('javelin', 0.27651146054267883),\n",
       " ('mineral', 0.2764323949813843),\n",
       " ('appointed', 0.2762989401817322),\n",
       " ('defiantly', 0.27625948190689087),\n",
       " ('strangled', 0.2757190465927124),\n",
       " ('strenuous', 0.27553224563598633),\n",
       " ('unsubdued', 0.2746509909629822),\n",
       " ('faint', 0.2745387852191925),\n",
       " ('corrugated', 0.274284303188324),\n",
       " ('wreathed', 0.27290722727775574),\n",
       " ('tracks', 0.27245765924453735),\n",
       " ('indescribably', 0.2724062204360962),\n",
       " ('measured', 0.27197521924972534),\n",
       " ('alpine', 0.27169713377952576),\n",
       " ('disapproving', 0.27160733938217163),\n",
       " ('thronged', 0.27150511741638184),\n",
       " ('sulked', 0.271401047706604),\n",
       " ('writhed', 0.2713389992713928),\n",
       " ('merriton', 0.2712925374507904),\n",
       " ('stoic', 0.2706886827945709),\n",
       " ('peculiar', 0.2688899338245392),\n",
       " ('wagged', 0.26864197850227356),\n",
       " ('shrewd', 0.26854628324508667),\n",
       " ('diseased', 0.26750850677490234),\n",
       " ('polar', 0.2668040990829468),\n",
       " ('coy', 0.2665916681289673),\n",
       " ('marinina', 0.26646512746810913),\n",
       " ('momentary', 0.26582860946655273),\n",
       " ('uncanny', 0.2655142545700073),\n",
       " ('toss', 0.2647809684276581),\n",
       " ('shortish', 0.2644951343536377),\n",
       " ('prominent', 0.2644628584384918),\n",
       " ('nobility', 0.26445308327674866),\n",
       " ('vitality', 0.26373085379600525),\n",
       " ('fiend', 0.2636096775531769),\n",
       " ('tour', 0.2631727457046509)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lawrence_sims = lawrence_model.wv.most_similar('queer', topn=100)  # get top100 similar words\n",
    "lawrence_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=8.403174994059926, pvalue=1.2082467883608112e-07)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(woolf_net_positive, l_net_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's add Gertrude Stein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\steincorpus.txt', encoding = 'latin-1') as f:\n",
    "    slines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21950 8958\n"
     ]
    }
   ],
   "source": [
    "sparagraphs = paragraphize(slines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.03317631781101227\n",
      "1 -0.0011414237087592483\n",
      "2 -0.20525439828634262\n",
      "3 -0.16443942114710808\n",
      "4 -0.09480139706283808\n",
      "5 -0.10035400278866291\n",
      "6 -0.17039267718791962\n",
      "7 -0.1037583127617836\n",
      "8 -0.13859378546476364\n",
      "9 -0.11977652087807655\n"
     ]
    }
   ],
   "source": [
    "s_sims = []\n",
    "s_pos_distances = []\n",
    "s_neg_distances = []\n",
    "s_net_positive = []\n",
    "\n",
    "for i in range(10):\n",
    "    ssample = choices(sparagraphs, k = len(sparagraphs))\n",
    "\n",
    "    # random.choices samples with repetition.\n",
    "    # So each time we run this, we're creating a different bootstrap sample of\n",
    "    # \"paragraphs\" from the sentence list.\n",
    "\n",
    "    #loading txt file and turning it into courpus\n",
    "    class MyCorpus:\n",
    "        def __iter__(self):\n",
    "            global ssample    \n",
    "            for line in ssample:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "    sentences = MyCorpus()\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences, iter=100, window=50)\n",
    "\n",
    "    sims = model.wv.most_similar('queer', topn=100)  # get other similar words\n",
    "    s_sims.append(sims)\n",
    "\n",
    "    pos_vector = get_vector(positive_words, model)\n",
    "    neg_vector = get_vector(negative_words, model)\n",
    "    vec_queer = model.wv['queer']\n",
    "    \n",
    "    pos_dist = cosine(vec_queer, pos_vector)\n",
    "    neg_dist = cosine(vec_queer, neg_vector)\n",
    "    s_pos_distances.append(pos_dist)\n",
    "    s_neg_distances.append(neg_dist)\n",
    "    \n",
    "    net_positive_queer = neg_dist - pos_dist\n",
    "    s_net_positive.append(net_positive_queer)\n",
    "    \n",
    "    print(i, net_positive_queer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=7.5096180678195825, pvalue=5.961016119615059e-07)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(woolf_net_positive, s_net_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"stein_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "stein_model = gensim.models.Word2Vec.load(\"stein_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "stein_vector = stein_model.wv['queer']  # get numpy vector of queer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spine', 0.35112884640693665),\n",
       " ('difficulty', 0.33443814516067505),\n",
       " ('oh', 0.31967729330062866),\n",
       " ('else', 0.31026601791381836),\n",
       " ('feeble', 0.3065449297428131),\n",
       " ('purpose', 0.3013850152492523),\n",
       " ('wonder', 0.29886555671691895),\n",
       " ('her', 0.29428794980049133),\n",
       " ('swing', 0.2936437129974365),\n",
       " ('bumping', 0.2902204096317291),\n",
       " ('wander', 0.28568530082702637),\n",
       " ('miserable', 0.2855188548564911),\n",
       " ('jam', 0.27957749366760254),\n",
       " ('rising', 0.2792643904685974),\n",
       " ('ralph', 0.2751308083534241),\n",
       " ('deceived', 0.27477478981018066),\n",
       " ('leila', 0.27413931488990784),\n",
       " ('mood', 0.2700275480747223),\n",
       " ('which', 0.26988616585731506),\n",
       " ('weak', 0.2684555649757385),\n",
       " ('pad', 0.26768413186073303),\n",
       " ('clasped', 0.2660280466079712),\n",
       " ('explained', 0.26557451486587524),\n",
       " ('immediately', 0.26470357179641724),\n",
       " ('nonsense', 0.2612372636795044),\n",
       " ('rack', 0.2593591511249542),\n",
       " ('performance', 0.2593272030353546),\n",
       " ('knelt', 0.25889265537261963),\n",
       " ('plainly', 0.25755518674850464),\n",
       " ('marriage', 0.25623178482055664),\n",
       " ('died', 0.2553948163986206),\n",
       " ('youthful', 0.25248903036117554),\n",
       " ('radiant', 0.24948066473007202),\n",
       " ('drawing', 0.24908077716827393),\n",
       " ('nails', 0.24877919256687164),\n",
       " ('careful', 0.2486906349658966),\n",
       " ('child', 0.24831882119178772),\n",
       " ('attention', 0.2480940818786621),\n",
       " ('reproached', 0.2473740130662918),\n",
       " ('effect', 0.24715013802051544),\n",
       " ('months', 0.24599909782409668),\n",
       " ('signs', 0.24577286839485168),\n",
       " ('light', 0.24488213658332825),\n",
       " ('married', 0.2429037094116211),\n",
       " ('eyelids', 0.24110746383666992),\n",
       " ('groan', 0.24091261625289917),\n",
       " ('cake', 0.24067014455795288),\n",
       " ('world', 0.23865282535552979),\n",
       " ('lament', 0.238594651222229),\n",
       " ('years', 0.23842550814151764),\n",
       " ('sleeves', 0.2377135008573532),\n",
       " ('terrible', 0.23704153299331665),\n",
       " ('tongue', 0.23698604106903076),\n",
       " ('cloth', 0.23665408790111542),\n",
       " ('pupils', 0.23446795344352722),\n",
       " ('state', 0.2332487255334854),\n",
       " ('mistake', 0.23235422372817993),\n",
       " ('shook', 0.23108980059623718),\n",
       " ('hotel', 0.2293848693370819),\n",
       " ('happiness', 0.22899237275123596),\n",
       " ('starting', 0.22883006930351257),\n",
       " ('roll', 0.22793163359165192),\n",
       " ('shouldn', 0.22688362002372742),\n",
       " ('sharply', 0.2266899049282074),\n",
       " ('tucking', 0.22448858618736267),\n",
       " ('it', 0.2232324481010437),\n",
       " ('postman', 0.22311878204345703),\n",
       " ('simply', 0.2220778465270996),\n",
       " ('came', 0.2219856083393097),\n",
       " ('innocent', 0.21991680562496185),\n",
       " ('cotton', 0.21931329369544983),\n",
       " ('organ', 0.21925340592861176),\n",
       " ('would', 0.2187781035900116),\n",
       " ('die', 0.21841023862361908),\n",
       " ('happy', 0.21824654936790466),\n",
       " ('sighed', 0.21729455888271332),\n",
       " ('titter', 0.21693286299705505),\n",
       " ('ten', 0.21526473760604858),\n",
       " ('pool', 0.2145576775074005),\n",
       " ('skin', 0.2140558958053589),\n",
       " ('blinds', 0.2140345275402069),\n",
       " ('barrel', 0.2137386053800583),\n",
       " ('calm', 0.2129920870065689),\n",
       " ('bodice', 0.2127770632505417),\n",
       " ('stomach', 0.2119590938091278),\n",
       " ('your', 0.2110549807548523),\n",
       " ('breathe', 0.20957840979099274),\n",
       " ('note', 0.20871715247631073),\n",
       " ('phrase', 0.20846620202064514),\n",
       " ('and', 0.20733681321144104),\n",
       " ('she', 0.2072441577911377),\n",
       " ('buddha', 0.20702588558197021),\n",
       " ('satisfaction', 0.20683664083480835),\n",
       " ('place', 0.20645692944526672),\n",
       " ('complete', 0.2057206630706787),\n",
       " ('clean', 0.2050660103559494),\n",
       " ('brass', 0.20504751801490784),\n",
       " ('neat', 0.20479607582092285),\n",
       " ('pounds', 0.2047717273235321),\n",
       " ('shape', 0.20320457220077515)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stein_sims = stein_model.wv.most_similar('queer', topn=100)  # get top100 similar words\n",
    "stein_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's try Mansfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\mansfieldcorpus.txt', encoding = 'latin-1') as f:\n",
    "    mlines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22071 4248\n"
     ]
    }
   ],
   "source": [
    "mparagraphs = paragraphize(mlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.2151273414492607\n",
      "1 -0.1086529940366745\n",
      "2 -0.14371636509895325\n",
      "3 -0.043794214725494385\n",
      "4 -0.1843266710639\n",
      "5 -0.09413588792085648\n",
      "6 -0.18851833045482635\n",
      "7 -0.06549833714962006\n",
      "8 -0.12879124283790588\n",
      "9 -0.004219874739646912\n"
     ]
    }
   ],
   "source": [
    "m_sims = []\n",
    "m_pos_distances = []\n",
    "m_neg_distances = []\n",
    "m_net_positive = []\n",
    "\n",
    "for i in range(10):\n",
    "    msample = choices(mparagraphs, k = len(mparagraphs))\n",
    "\n",
    "    # random.choices samples with repetition.\n",
    "    # So each time we run this, we're creating a different bootstrap sample of\n",
    "    # \"paragraphs\" from the sentence list.\n",
    "\n",
    "    #loading txt file and turning it into courpus\n",
    "    class MyCorpus:\n",
    "        def __iter__(self):\n",
    "            global msample    \n",
    "            for line in msample:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "    sentences = MyCorpus()\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences, iter=100)\n",
    "\n",
    "    sims = model.wv.most_similar('queer', topn=100)  # get other similar words\n",
    "    m_sims.append(sims)\n",
    "\n",
    "    pos_vector = get_vector(positive_words, model)\n",
    "    neg_vector = get_vector(negative_words, model)\n",
    "    vec_queer = model.wv['queer']\n",
    "    \n",
    "    pos_dist = cosine(vec_queer, pos_vector)\n",
    "    neg_dist = cosine(vec_queer, neg_vector)\n",
    "    m_pos_distances.append(pos_dist)\n",
    "    m_neg_distances.append(neg_dist)\n",
    "    \n",
    "    net_positive_queer = neg_dist - pos_dist\n",
    "    m_net_positive.append(net_positive_queer)\n",
    "    \n",
    "    print(i, net_positive_queer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"mansfield_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "mansfield_model = gensim.models.Word2Vec.load(\"mansfield_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "mansfield_vector = mansfield_model.wv['queer']  # get numpy vector of queer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yet', 0.39512407779693604),\n",
       " ('beatrice', 0.36514517664909363),\n",
       " ('joined', 0.3358542323112488),\n",
       " ('quivered', 0.3354937434196472),\n",
       " ('drawing', 0.3348598778247833),\n",
       " ('secret', 0.3263881802558899),\n",
       " ('crying', 0.3209666609764099),\n",
       " ('wonderful', 0.32064521312713623),\n",
       " ('glance', 0.31881457567214966),\n",
       " ('mackintosh', 0.31478744745254517),\n",
       " ('keeping', 0.3126864433288574),\n",
       " ('spine', 0.3011530637741089),\n",
       " ('faintly', 0.29576122760772705),\n",
       " ('sentence', 0.28777241706848145),\n",
       " ('brilliant', 0.2874719500541687),\n",
       " ('concerned', 0.2829946279525757),\n",
       " ('idea', 0.27779802680015564),\n",
       " ('struck', 0.2725956439971924),\n",
       " ('gilt', 0.2724136710166931),\n",
       " ('marie', 0.27232080698013306),\n",
       " ('foreign', 0.2702065110206604),\n",
       " ('hurt', 0.2657381296157837),\n",
       " ('danced', 0.2648789882659912),\n",
       " ('for', 0.2644995450973511),\n",
       " ('bitter', 0.26263657212257385),\n",
       " ('reggie', 0.2617475390434265),\n",
       " ('and', 0.25989818572998047),\n",
       " ('herself', 0.2596359848976135),\n",
       " ('things', 0.25827670097351074),\n",
       " ('pain', 0.2551203966140747),\n",
       " ('strain', 0.254585325717926),\n",
       " ('grow', 0.2540949583053589),\n",
       " ('bowl', 0.2536347806453705),\n",
       " ('carsfield', 0.25331470370292664),\n",
       " ('mocked', 0.24926689267158508),\n",
       " ('sensation', 0.2480490654706955),\n",
       " ('bold', 0.24506261944770813),\n",
       " ('benches', 0.24503196775913239),\n",
       " ('telling', 0.24447327852249146),\n",
       " ('came', 0.24382805824279785),\n",
       " ('pouring', 0.24322110414505005),\n",
       " ('intensely', 0.24229267239570618),\n",
       " ('nod', 0.24192482233047485),\n",
       " ('flight', 0.2414698600769043),\n",
       " ('attention', 0.24075238406658173),\n",
       " ('pursed', 0.23959681391716003),\n",
       " ('shadow', 0.23802559077739716),\n",
       " ('brightly', 0.23576635122299194),\n",
       " ('nearly', 0.23537421226501465),\n",
       " ('hugging', 0.2342313826084137),\n",
       " ('possible', 0.23190884292125702),\n",
       " ('jet', 0.23157423734664917),\n",
       " ('buddha', 0.23152998089790344),\n",
       " ('finally', 0.23102954030036926),\n",
       " ('gushing', 0.22953641414642334),\n",
       " ('stealthily', 0.22759447991847992),\n",
       " ('third', 0.22717103362083435),\n",
       " ('shall', 0.2266831398010254),\n",
       " ('mistake', 0.22499480843544006),\n",
       " ('deliberately', 0.2242933064699173),\n",
       " ('dared', 0.22413142025470734),\n",
       " ('snapped', 0.22402527928352356),\n",
       " ('sent', 0.22397349774837494),\n",
       " ('silently', 0.22235868871212006),\n",
       " ('rage', 0.22219030559062958),\n",
       " ('lightning', 0.22177164256572723),\n",
       " ('tight', 0.22071906924247742),\n",
       " ('express', 0.21980862319469452),\n",
       " ('comfortable', 0.2196153700351715),\n",
       " ('handkerchief', 0.21881327033042908),\n",
       " ('joy', 0.21823978424072266),\n",
       " ('funerals', 0.21727493405342102),\n",
       " ('cashier', 0.21689756214618683),\n",
       " ('passage', 0.21686626970767975),\n",
       " ('blow', 0.21681174635887146),\n",
       " ('peered', 0.21676050126552582),\n",
       " ('sharply', 0.21615609526634216),\n",
       " ('jug', 0.21435554325580597),\n",
       " ('lucky', 0.2140512466430664),\n",
       " ('fumbled', 0.2135155200958252),\n",
       " ('stomach', 0.213051438331604),\n",
       " ('quiver', 0.21177250146865845),\n",
       " ('parted', 0.2108093798160553),\n",
       " ('trouble', 0.20915833115577698),\n",
       " ('played', 0.20851175487041473),\n",
       " ('vivid', 0.20799347758293152),\n",
       " ('respectable', 0.20679421722888947),\n",
       " ('toe', 0.20671918988227844),\n",
       " ('voyage', 0.2067185342311859),\n",
       " ('soul', 0.2062448412179947),\n",
       " ('shouldn', 0.20590978860855103),\n",
       " ('company', 0.20580118894577026),\n",
       " ('sparks', 0.2053738534450531),\n",
       " ('true', 0.20486021041870117),\n",
       " ('sold', 0.20476259291172028),\n",
       " ('strange', 0.20449036359786987),\n",
       " ('wouldn', 0.20433515310287476),\n",
       " ('appeared', 0.20407502353191376),\n",
       " ('vous', 0.20396828651428223),\n",
       " ('or', 0.20350345969200134)]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mansfield_sims = mansfield_model.wv.most_similar('queer', topn=100)  # get top100 similar words\n",
    "mansfield_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=7.2324241663652975, pvalue=9.993124513616901e-07)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(woolf_net_positive, m_net_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's add Joseph Conrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Heejoung Shin\\\\Documents\\\\Heejoung Files\\\\UIUC MSLIS\\\\IS417-Data Science in the Humanities\\\\Research Paper\\\\Data\\\\conradcorpus.txt', encoding = 'latin-1') as f:\n",
    "    clines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200460 43875\n"
     ]
    }
   ],
   "source": [
    "cparagraphs = paragraphize(clines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.041653066873550415\n",
      "1 0.03466230630874634\n",
      "2 0.027008473873138428\n",
      "3 0.02608388662338257\n",
      "4 0.02556060254573822\n",
      "5 0.00840313732624054\n",
      "6 0.02373473346233368\n",
      "7 0.034248724579811096\n",
      "8 0.002868056297302246\n",
      "9 0.04377853870391846\n"
     ]
    }
   ],
   "source": [
    "c_sims = []\n",
    "c_pos_distances = []\n",
    "c_neg_distances = []\n",
    "c_net_positive = []\n",
    "\n",
    "for i in range(10):\n",
    "    csample = choices(cparagraphs, k = len(cparagraphs))\n",
    "\n",
    "    # random.choices samples with repetition.\n",
    "    # So each time we run this, we're creating a different bootstrap sample of\n",
    "    # \"paragraphs\" from the sentence list.\n",
    "\n",
    "    #loading txt file and turning it into courpus\n",
    "    class MyCorpus:\n",
    "        def __iter__(self):\n",
    "            global csample    \n",
    "            for line in csample:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "    sentences = MyCorpus()\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences, iter=10)\n",
    "\n",
    "    sims = model.wv.most_similar('queer', topn=100)  # get other similar words\n",
    "    c_sims.append(sims)\n",
    "\n",
    "    pos_vector = get_vector(positive_words, model)\n",
    "    neg_vector = get_vector(negative_words, model)\n",
    "    vec_queer = model.wv['queer']\n",
    "    \n",
    "    pos_dist = cosine(vec_queer, pos_vector)\n",
    "    neg_dist = cosine(vec_queer, neg_vector)\n",
    "    c_pos_distances.append(pos_dist)\n",
    "    c_neg_distances.append(neg_dist)\n",
    "    \n",
    "    net_positive_queer = neg_dist - pos_dist\n",
    "    c_net_positive.append(net_positive_queer)\n",
    "    \n",
    "    print(i, net_positive_queer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conrad t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.2693442155432015, pvalue=0.22048577931603436)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(woolf_net_positive, c_net_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplotdata = ({'net_positivity': woolf_net_positive + j_net_positive + f_net_positive + l_net_positive + s_net_positive + m_net_positive, 'author': ['Woolf'] * 10 + ['Joyce'] * 10 + ['Fitzgerald'] * 10 + ['Lawrence'] * 10 + ['Stein'] * 10 + ['Mansfield'] * 10})\n",
    "# boxplotdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(20, 10)})\n",
    "sns_plot = sns.boxplot(x = 'author', y = 'net_positivity', data = boxplotdata)\n",
    "fig = sns_plot.get_figure()\n",
    "plt.title(\"Stability Test for All Authors\")\n",
    "fig.savefig(\"boxplot_sixauthors.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
